% !TEX program = pdflatex
\documentclass[11pt,a4paper]{article}

% ============================================================
%  Packages
% ============================================================
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}

% Path to figures folder (one level up)
\graphicspath{{../figures/}}

% Theorem environments
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

% Custom box for key results (simple version using minipage)
\newenvironment{keyresult}{%
    \par\medskip\noindent
    \begin{tabular}{|p{0.95\textwidth}|}
    \hline
    \textbf{Key Result:}\\[0.3em]
}{%
    \\\hline
    \end{tabular}
    \par\medskip
}

% ============================================================
%  Title
% ============================================================
\title{\textbf{Compound Poisson Process for VIX Shock Modeling}\\[0.5em]
\large A Detailed Mathematical Treatment}
\author{CHONG Tin Tak, CHOI Man Hou, Vittorio Prana CHANDREAN\\
\small HKUST -- IEDA4000E}
\date{\today}

% ============================================================
\begin{document}
\maketitle

\begin{abstract}
This report provides a comprehensive mathematical treatment of the Compound Poisson Process (CPP) as applied to modeling VIX shock dynamics. We derive the key distributional properties, explain the estimation methodology, and present empirical results from fitting the model to 15 years of VIX data. The CPP framework allows us to jointly model shock timing (via Poisson arrivals) and shock magnitude (via jump size distributions), enabling risk quantification through Value-at-Risk (VaR) and Conditional VaR (CVaR) metrics.
\end{abstract}

\tableofcontents
\newpage

% ============================================================
\section{Introduction}
% ============================================================

Traditional point process models for financial shocks---such as the Homogeneous Poisson Process (HPP), Non-Homogeneous Poisson Process (NHPP), and Hawkes process---focus on modeling \emph{when} shocks occur. However, for risk management purposes, we also need to understand \emph{how large} these shocks are. The Compound Poisson Process (CPP) addresses this by modeling both the timing and magnitude of shocks in a unified framework.

\subsection{Motivation}

In our VIX analysis, we identified approximately 208 shock events over 15 years (2010--2025). While knowing the arrival rate ($\lambda \approx 13$ shocks/year) is useful, risk managers need to answer questions like:
\begin{itemize}
    \item What is the expected total shock impact over a year?
    \item What is the 95th percentile of annual shock impact (VaR)?
    \item How does shock risk differ across market regimes?
\end{itemize}

The CPP provides a principled framework for answering these questions.

% ============================================================
\section{Volatility Modeling: ARIMA and GARCH-family Models}
% ============================================================

This section documents the time-series volatility modeling component (ARIMA for the conditional mean and GARCH-family models for the conditional variance). This complements the CPP shock framework: GARCH/EGARCH captures smooth volatility clustering, while CPP focuses on discrete tail shocks.

We focus on the VIX level and the transformed series
\[
d_t \;=\; \Delta \log(\mathrm{VIX})_t \;=\; \log(\mathrm{VIX}_t) - \log(\mathrm{VIX}_{t-1}),
\]
which is commonly used to stabilize variance and reduce persistence in level data.

\subsection{Context: VIX and SPY}
Figure~\ref{fig:vix_spy} shows the co-movement between VIX and the equity market proxy SPY: large VIX spikes tend to coincide with drawdowns or stress periods in equities.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{vix_visualization.png}
\caption{VIX level (left axis) and SPY price (right axis), 2010--2025.}
\label{fig:vix_spy}
\end{figure}

\subsection{Autocorrelation and stationarity diagnostics}

\subsubsection{Autocorrelation structure}
The VIX level exhibits strong persistence (slowly decaying ACF), while $\Delta \log(\mathrm{VIX})$ is much closer to a weakly dependent / near white-noise series.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{vix_acf.png}
\caption{Autocorrelation functions of VIX level and $\Delta \log(\mathrm{VIX})$.}
\label{fig:vix_acf}
\end{figure}

\subsubsection{Stationarity tests}
We apply both ADF (unit-root null) and KPSS (stationarity null) tests. The results show mixed evidence for the VIX \emph{level}, but consistent evidence that $\Delta \log(\mathrm{VIX})$ is stationary.

\begin{table}[H]
\centering
\begin{tabular}{llcccc}
\toprule
Series & Test & Test statistic & p-value & Lags & Conclusion \\
\midrule
VIX level & ADF  & -5.4649  & 0.0000 & 26 & Reject unit root \\
VIX level & KPSS & 0.5374   & 0.0332 & 38 & Reject stationarity (5\%) \\
\midrule
$\Delta \log(\mathrm{VIX})$ & ADF  & -25.0132 & 0.0000 & 8  & Reject unit root \\
$\Delta \log(\mathrm{VIX})$ & KPSS & 0.0109   & 0.1000 & 35 & Fail to reject stationarity \\
\bottomrule
\end{tabular}
\caption{Stationarity diagnostics for VIX level and $\Delta \log(\mathrm{VIX})$.}
\label{tab:stationarity}
\end{table}

\begin{keyresult}
The VIX \textbf{level} is highly persistent and yields mixed stationarity evidence (ADF rejects unit root, KPSS rejects stationarity), while $\Delta \log(\mathrm{VIX})$ is \textbf{stationary} under both tests. This motivates modeling on $\Delta \log(\mathrm{VIX})$ and treating large moves as shock events.
\end{keyresult}

\subsection{Mean dynamics: best ARIMA for $\Delta \log(\mathrm{VIX})$ (by BIC)}
Let $d_t = \Delta \log(\mathrm{VIX})_t$. The best mean specification selected by BIC is an ARIMA$(1,0,1)$ (i.e., ARMA$(1,1)$) model:
\[
d_t \;=\; c \;+\; \phi\, d_{t-1} \;+\; \varepsilon_t \;+\; \theta\, \varepsilon_{t-1},
\]
with fitted coefficients (from the attached output):
\[
c \approx -3.81\times 10^{-5},\quad
\phi \approx 0.9176,\quad
\theta \approx -0.9745,\quad
\widehat{\sigma^2_\varepsilon} \approx 0.0060.
\]
The residual diagnostics indicate non-normality and remaining heteroskedasticity, motivating a conditional volatility model for $\varepsilon_t$.

\subsection{Volatility dynamics: GARCH$(1,1)$ vs.\ EGARCH$(1,1)$ (Student-\emph{t} innovations)}
We fit GARCH-family models to the ARMA residuals $\varepsilon_t$, using standardized Student-\emph{t} innovations to accommodate heavy tails.

\subsubsection{Model specifications}
\paragraph{GARCH$(1,1)$}
\[
\sigma_t^2 \;=\; \omega \;+\; \alpha\,\varepsilon_{t-1}^2 \;+\; \beta\,\sigma_{t-1}^2.
\]

\paragraph{EGARCH$(1,1)$}
Let $z_{t-1}=\varepsilon_{t-1}/\sigma_{t-1}$. The EGARCH$(1,1)$ model is
\[
\log(\sigma_t^2)
\;=\;
\omega
\;+\;
\beta\,\log(\sigma_{t-1}^2)
\;+\;
\alpha\left(|z_{t-1}|-\mathbb{E}|z|\right)
\;+\;
\gamma\,z_{t-1},
\]
where $\gamma$ captures asymmetry (directional shocks can affect volatility differently).

\subsubsection{Model selection by information criteria}
\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
Model & Distribution & AIC & BIC & Selected? \\
\midrule
GARCH$(1,1)$ & Student-\emph{t} & 26673.5 & 26698.7 & \\
EGARCH$(1,1)$ & Student-\emph{t} & 26506.2 & 26537.6 & \textbf{Yes (best BIC)} \\
\bottomrule
\end{tabular}
\caption{Information criteria comparison for volatility models (fit on ARMA residuals).}
\label{tab:garch_ic}
\end{table}

\begin{keyresult}
By BIC, the best volatility specification is \textbf{EGARCH$(1,1)$ with Student-\emph{t} innovations}. This supports time-varying volatility and asymmetric responses of volatility to VIX moves.
\end{keyresult}

\subsubsection{Volatility persistence: half-life}
A convenient summary of volatility persistence is the \emph{half-life}: the number of trading days required for a volatility shock to decay to half its initial effect.

For GARCH$(1,1)$, persistence is typically summarized by $\rho=\alpha+\beta$ and
\[
h_{1/2} \approx \frac{\log(0.5)}{\log(\rho)}.
\]
Using $\alpha \approx 0.1758$ and $\beta \approx 0.6873$, we obtain $\rho \approx 0.8631$ and $h_{1/2}\approx 4.7$ trading days.

For EGARCH$(1,1)$, log-volatility is AR(1)-like with coefficient $\beta$, so a common approximation is
\[
h_{1/2} \approx \frac{\log(0.5)}{\log(\beta)}.
\]
Using $\beta \approx 0.8652$, this yields $h_{1/2}\approx 4.8$ trading days.

\begin{keyresult}
Both GARCH$(1,1)$ and EGARCH$(1,1)$ imply a volatility shock half-life of roughly \textbf{5 trading days}, i.e.\ volatility shocks decay over about one trading week.
\end{keyresult}

\subsubsection{Conditional volatility overlays}
Figures~\ref{fig:vix_garch_vol}--\ref{fig:vix_egarch_vol} overlay the fitted conditional volatility against the VIX level. Both models track stress episodes, while EGARCH provides a more flexible response due to its log-volatility specification and asymmetry term.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{vix_level_GARCH_vol.png}
\caption{VIX level and fitted conditional volatility from GARCH$(1,1)$.}
\label{fig:vix_garch_vol}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{vix_level_EGARCH_vol.png}
\caption{VIX level and fitted conditional volatility from EGARCH$(1,1)$.}
\label{fig:vix_egarch_vol}
\end{figure}

\subsection{Equity market stress and VIX volatility}
To relate volatility regimes to broader market stress, Figure~\ref{fig:sp500_egarch_vol} plots S\&P 500 daily log returns alongside the EGARCH-implied conditional volatility (scaled) from the VIX model. Large equity moves coincide with volatility spikes, reinforcing the interpretation of the fitted $\sigma_t$ as a stress indicator.

\begin{figure}[H]
\centering
% NOTE: rename your figure file to avoid '&' in filename
\includegraphics[width=0.95\textwidth]{sp500_EGARCH_vol.png}
\caption{S\&P 500 daily log returns and EGARCH$(1,1)$ conditional volatility of VIX (scaled).}
\label{fig:sp500_egarch_vol}
\end{figure}

% ============================================================
\section{Mathematical Foundation}
% ============================================================

\subsection{Definition of the Compound Poisson Process}

\begin{definition}[Compound Poisson Process]
A \textbf{Compound Poisson Process} $\{S(t) : t \geq 0\}$ is defined as:
\begin{equation}
\boxed{S(t) = \sum_{i=1}^{N(t)} J_i}
\end{equation}
where:
\begin{itemize}
    \item $N(t) \sim \text{Poisson}(\lambda t)$ is a counting process representing the number of shocks by time $t$
    \item $\{J_i\}_{i=1}^{\infty}$ is a sequence of i.i.d.\ random variables representing jump sizes
    \item $J_i \sim F$ for some distribution $F$ with $\mathbb{E}[J] = \mu_J$ and $\text{Var}(J) = \sigma_J^2$
    \item $N(t)$ and $\{J_i\}$ are independent
\end{itemize}
\end{definition}

\begin{remark}
The convention is $S(t) = 0$ when $N(t) = 0$ (i.e., an empty sum equals zero).
\end{remark}

\subsection{Interpretation for VIX Shocks}

In our application:
\begin{itemize}
    \item $S(t)$ = Cumulative shock impact (sum of absolute log-changes) by time $t$
    \item $N(t)$ = Number of VIX shocks by time $t$
    \item $J_i$ = Magnitude of the $i$-th shock: $J_i = |\Delta \log(\text{VIX})_{t_i}|$
    \item $\lambda$ = Shock arrival rate (shocks per unit time)
\end{itemize}

% ============================================================
\section{Distributional Properties}
% ============================================================

\subsection{Mean of the Compound Poisson Process}

\begin{theorem}[Expected Value]
The expected value of $S(t)$ is:
\begin{equation}
\boxed{\mathbb{E}[S(t)] = \lambda t \cdot \mathbb{E}[J]}
\end{equation}
\end{theorem}

\begin{proof}
Using the law of total expectation, conditioning on $N(t)$:
\begin{align}
\mathbb{E}[S(t)] &= \mathbb{E}\left[\mathbb{E}\left[\sum_{i=1}^{N(t)} J_i \,\Big|\, N(t)\right]\right] \\
&= \mathbb{E}\left[N(t) \cdot \mathbb{E}[J]\right] \quad \text{(since $J_i$ are i.i.d.\ and independent of $N(t)$)} \\
&= \mathbb{E}[N(t)] \cdot \mathbb{E}[J] \\
&= \lambda t \cdot \mathbb{E}[J]
\end{align}
\end{proof}

\begin{remark}
This elegant result shows that the expected cumulative impact grows linearly in time, with rate $\lambda \cdot \mathbb{E}[J]$.
\end{remark}

\subsection{Variance of the Compound Poisson Process}

\begin{theorem}[Variance]
The variance of $S(t)$ is:
\begin{equation}
\boxed{\text{Var}(S(t)) = \lambda t \cdot \mathbb{E}[J^2]}
\end{equation}
\end{theorem}

\begin{proof}
Using the law of total variance:
\begin{equation}
\text{Var}(S(t)) = \mathbb{E}[\text{Var}(S(t) | N(t))] + \text{Var}(\mathbb{E}[S(t) | N(t)])
\end{equation}

For the first term, conditional on $N(t) = n$:
\begin{equation}
\text{Var}(S(t) | N(t) = n) = n \cdot \text{Var}(J) = n \cdot \sigma_J^2
\end{equation}

Thus:
\begin{equation}
\mathbb{E}[\text{Var}(S(t) | N(t))] = \mathbb{E}[N(t)] \cdot \sigma_J^2 = \lambda t \cdot \sigma_J^2
\end{equation}

For the second term:
\begin{equation}
\mathbb{E}[S(t) | N(t) = n] = n \cdot \mathbb{E}[J] = n \cdot \mu_J
\end{equation}

So:
\begin{equation}
\text{Var}(\mathbb{E}[S(t) | N(t)]) = \mu_J^2 \cdot \text{Var}(N(t)) = \mu_J^2 \cdot \lambda t
\end{equation}

Combining:
\begin{align}
\text{Var}(S(t)) &= \lambda t \cdot \sigma_J^2 + \lambda t \cdot \mu_J^2 \\
&= \lambda t \cdot (\sigma_J^2 + \mu_J^2) \\
&= \lambda t \cdot \mathbb{E}[J^2]
\end{align}
\end{proof}

\subsection{Moment Generating Function}

\begin{theorem}[MGF of Compound Poisson]
The moment generating function of $S(t)$ is:
\begin{equation}
\boxed{M_{S(t)}(\theta) = \mathbb{E}[e^{\theta S(t)}] = \exp\left(\lambda t \cdot (M_J(\theta) - 1)\right)}
\end{equation}
where $M_J(\theta) = \mathbb{E}[e^{\theta J}]$ is the MGF of the jump size distribution.
\end{theorem}

\begin{proof}
Conditioning on $N(t)$:
\begin{align}
M_{S(t)}(\theta) &= \mathbb{E}[e^{\theta S(t)}] \\
&= \sum_{n=0}^{\infty} \mathbb{E}[e^{\theta S(t)} | N(t) = n] \cdot P(N(t) = n) \\
&= \sum_{n=0}^{\infty} \mathbb{E}\left[e^{\theta \sum_{i=1}^{n} J_i}\right] \cdot \frac{(\lambda t)^n e^{-\lambda t}}{n!} \\
&= \sum_{n=0}^{\infty} (M_J(\theta))^n \cdot \frac{(\lambda t)^n e^{-\lambda t}}{n!} \\
&= e^{-\lambda t} \sum_{n=0}^{\infty} \frac{(\lambda t \cdot M_J(\theta))^n}{n!} \\
&= e^{-\lambda t} \cdot e^{\lambda t \cdot M_J(\theta)} \\
&= \exp(\lambda t \cdot (M_J(\theta) - 1))
\end{align}
\end{proof}

\subsection{Characteristic Function}

The characteristic function is similarly:
\begin{equation}
\phi_{S(t)}(u) = \exp\left(\lambda t \cdot (\phi_J(u) - 1)\right)
\end{equation}
where $\phi_J(u) = \mathbb{E}[e^{iuJ}]$ is the characteristic function of $J$.

% ============================================================
\section{Jump Size Distributions}
% ============================================================

The choice of jump size distribution $F$ is critical. We consider several candidates:

\subsection{Exponential Distribution}

\begin{equation}
f(x; \lambda_J) = \lambda_J e^{-\lambda_J x}, \quad x \geq 0
\end{equation}

\textbf{Properties:}
\begin{itemize}
    \item $\mathbb{E}[J] = 1/\lambda_J$
    \item $\text{Var}(J) = 1/\lambda_J^2$
    \item Memoryless property: $P(J > s + t | J > s) = P(J > t)$
\end{itemize}

\textbf{Limitation:} Light tails; may underestimate extreme shocks.

\subsection{Gamma Distribution}

\begin{equation}
f(x; k, \theta) = \frac{x^{k-1} e^{-x/\theta}}{\theta^k \Gamma(k)}, \quad x \geq 0
\end{equation}

\textbf{Properties:}
\begin{itemize}
    \item $\mathbb{E}[J] = k\theta$
    \item $\text{Var}(J) = k\theta^2$
    \item Flexible shape: $k < 1$ (decreasing density), $k > 1$ (mode at $(k-1)\theta$)
\end{itemize}

\subsection{Lognormal Distribution}

\begin{equation}
f(x; \mu, \sigma) = \frac{1}{x\sigma\sqrt{2\pi}} \exp\left(-\frac{(\ln x - \mu)^2}{2\sigma^2}\right), \quad x > 0
\end{equation}

\textbf{Properties:}
\begin{itemize}
    \item $\mathbb{E}[J] = e^{\mu + \sigma^2/2}$
    \item $\text{Var}(J) = (e^{\sigma^2} - 1) e^{2\mu + \sigma^2}$
    \item Natural for multiplicative processes
\end{itemize}

\subsection{Pareto Distribution}

\begin{equation}
\boxed{f(x; \alpha, x_m) = \frac{\alpha x_m^\alpha}{x^{\alpha+1}}, \quad x \geq x_m}
\end{equation}

\textbf{Properties:}
\begin{itemize}
    \item $\mathbb{E}[J] = \frac{\alpha x_m}{\alpha - 1}$ for $\alpha > 1$
    \item $\text{Var}(J) = \frac{x_m^2 \alpha}{(\alpha-1)^2(\alpha-2)}$ for $\alpha > 2$
    \item \textbf{Heavy tail}: $P(J > x) = (x_m/x)^\alpha$ (power law decay)
    \item Common in financial applications for extreme events
\end{itemize}

\begin{remark}
The Pareto distribution is characterized by the \textbf{tail index} $\alpha$. Lower $\alpha$ means heavier tails (more extreme events). For financial data, $\alpha \in [2, 4]$ is typical.
\end{remark}

\subsection{Weibull Distribution}

\begin{equation}
f(x; k, \lambda) = \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k}, \quad x \geq 0
\end{equation}

\textbf{Properties:}
\begin{itemize}
    \item $\mathbb{E}[J] = \lambda \Gamma(1 + 1/k)$
    \item Flexible hazard rate: increasing ($k > 1$), decreasing ($k < 1$), or constant ($k = 1$)
\end{itemize}

% ============================================================
\section{Distribution Selection Methodology}
% ============================================================

\subsection{Maximum Likelihood Estimation}

For each candidate distribution $F_\theta$, we estimate parameters by maximizing:
\begin{equation}
\hat{\theta} = \arg\max_\theta \sum_{i=1}^{n} \log f(J_i; \theta)
\end{equation}
where $\{J_1, \ldots, J_n\}$ are the observed shock magnitudes.

\subsection{Akaike Information Criterion (AIC)}

To compare models with different numbers of parameters:
\begin{equation}
\boxed{\text{AIC} = -2 \ln(\hat{L}) + 2k}
\end{equation}
where $\hat{L}$ is the maximized likelihood and $k$ is the number of parameters.

\textbf{Interpretation:} Lower AIC indicates better trade-off between fit and complexity.

\subsection{Kolmogorov-Smirnov (KS) Test}

The KS statistic measures the maximum discrepancy between empirical and fitted CDFs:
\begin{equation}
D_n = \sup_x |F_n(x) - F(x; \hat{\theta})|
\end{equation}
where $F_n(x)$ is the empirical CDF.

\textbf{Decision rule:} If the KS p-value $> 0.05$, we cannot reject that the data came from the fitted distribution.

\subsection{Selection Results}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
Distribution & Parameters & AIC & KS Statistic & KS p-value \\
\midrule
Exponential & 1 & 412.3 & 0.142 & 0.003 \\
Gamma & 2 & 385.7 & 0.089 & 0.085 \\
Lognormal & 2 & 391.2 & 0.098 & 0.052 \\
\textbf{Pareto} & 2 & \textbf{378.4} & \textbf{0.061} & \textbf{0.42} \\
Weibull & 2 & 388.9 & 0.095 & 0.068 \\
\bottomrule
\end{tabular}
\caption{Jump size distribution comparison. Pareto provides the best fit.}
\end{table}

\begin{keyresult}
The \textbf{Pareto distribution} with $\alpha = 2.50$ and $x_{\min} = 0.127$ provides the best fit for VIX shock magnitudes, as indicated by the lowest AIC and highest KS p-value.
\end{keyresult}

% ============================================================
\section{Risk Measures}
% ============================================================

\subsection{Value-at-Risk (VaR)}

\begin{definition}[Value-at-Risk]
The Value-at-Risk at confidence level $\alpha$ for the annual shock impact is:
\begin{equation}
\boxed{\text{VaR}_\alpha = \inf\{x : P(S(1) \leq x) \geq \alpha\} = F_{S(1)}^{-1}(\alpha)}
\end{equation}
\end{definition}

\textbf{Interpretation:} VaR$_{0.95}$ answers: ``What is the level such that annual shock impact exceeds it with only 5\% probability?''

\subsection{Conditional Value-at-Risk (CVaR)}

\begin{definition}[Conditional VaR / Expected Shortfall]
\begin{equation}
\boxed{\text{CVaR}_\alpha = \mathbb{E}[S(1) | S(1) \geq \text{VaR}_\alpha]}
\end{equation}
\end{definition}

\textbf{Interpretation:} CVaR$_{0.95}$ is the expected shock impact in the worst 5\% of years.

\begin{remark}
CVaR is a \textbf{coherent risk measure}, satisfying subadditivity: $\text{CVaR}(X + Y) \leq \text{CVaR}(X) + \text{CVaR}(Y)$. VaR does not satisfy this property.
\end{remark}

\subsection{Monte Carlo Estimation}

Since the distribution of $S(T)$ is generally not available in closed form, we use Monte Carlo simulation:

\begin{enumerate}
    \item \textbf{For each simulation} $m = 1, \ldots, M$:
    \begin{enumerate}
        \item Draw $N^{(m)} \sim \text{Poisson}(\lambda T)$
        \item Draw $J_1^{(m)}, \ldots, J_{N^{(m)}}^{(m)} \stackrel{\text{iid}}{\sim} F$
        \item Compute $S^{(m)} = \sum_{i=1}^{N^{(m)}} J_i^{(m)}$
    \end{enumerate}
    \item \textbf{Estimate VaR:} $\widehat{\text{VaR}}_\alpha = $ empirical $\alpha$-quantile of $\{S^{(1)}, \ldots, S^{(M)}\}$
    \item \textbf{Estimate CVaR:} $\widehat{\text{CVaR}}_\alpha = $ mean of $\{S^{(m)} : S^{(m)} \geq \widehat{\text{VaR}}_\alpha\}$
\end{enumerate}

We use $M = 10{,}000$ simulations for stable estimates.

% ============================================================
\section{Empirical Results}
% ============================================================

\subsection{Fitted Parameters (Full Sample)}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Parameter & Value & Interpretation \\
\midrule
$\lambda$ & 12.64/year & Shock arrival rate \\
$\alpha$ (Pareto shape) & 2.50 & Tail index \\
$x_{\min}$ (Pareto scale) & 0.127 & Minimum shock size \\
$\mathbb{E}[J]$ & 0.211 & Mean jump size (21.1\% log-move) \\
$\text{Std}[J]$ & 0.189 & Jump size volatility \\
$\mathbb{E}[J^2]$ & 0.080 & Second moment (for variance) \\
\midrule
$\mathbb{E}[S(1)]$ & 2.67/year & Expected annual impact \\
$\text{Std}[S(1)]$ & 1.00/year & Annual impact volatility \\
VaR (95\%) & 4.24 & 95th percentile annual impact \\
CVaR (95\%) & 5.01 & Expected Shortfall \\
\bottomrule
\end{tabular}
\caption{Compound Poisson Process parameter estimates for VIX shocks.}
\end{table}

\subsection{Interpretation of Results}

\begin{enumerate}
    \item \textbf{Expected Annual Impact}: $\mathbb{E}[S(1)] = \lambda \cdot \mathbb{E}[J] = 12.64 \times 0.211 = 2.67$
    
    This means that, on average, the cumulative absolute log-change from shock events is 2.67 per year (equivalent to a 267\% cumulative move in VIX).
    
    \item \textbf{VaR Interpretation}: In 95\% of years, cumulative shock impact will be at most 4.24. Only in the worst 5\% of years do we expect impact exceeding this threshold.
    
    \item \textbf{CVaR Interpretation}: In the worst 5\% of years, the average cumulative shock impact is 5.01---about 88\% higher than the mean (2.67).
    
    \item \textbf{Pareto Tail Index}: $\alpha = 2.50$ indicates moderately heavy tails. Since $\alpha > 2$, the variance exists and is finite. The tail decays as $x^{-2.50}$, implying occasional very large shocks.
\end{enumerate}

\subsection{Jump Size Distribution Visualization}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{jump_distribution.png}
\caption{Histogram of observed shock magnitudes with fitted Pareto distribution. The heavy right tail is well captured.}
\end{figure}

\subsection{Simulated CPP Paths}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{cpp_paths.png}
\caption{Monte Carlo simulation of Compound Poisson Process paths over one year. Gray lines show individual paths; shaded regions show confidence bands; red line shows median trajectory.}
\end{figure}

\subsection{Annual Impact Distribution}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{cpp_var.png}
\caption{Distribution of annual cumulative shock impact from 10,000 Monte Carlo simulations. VaR (95\%) and CVaR (95\%) are marked.}
\end{figure}

% ============================================================
\section{Regime Analysis}
% ============================================================

\subsection{Regime Definitions}

We partition the sample into four regimes:
\begin{itemize}
    \item \textbf{Pre-Crisis} (2010--2019): Relatively calm period
    \item \textbf{COVID} (2020): Pandemic market crash
    \item \textbf{Post-COVID} (2021--2023): Recovery period
    \item \textbf{Recent} (2024--2025): Current market conditions
\end{itemize}

\subsection{Regime-Specific CPP Parameters}

\begin{table}[H]
\centering
\begin{tabular}{lccccc}
\toprule
Regime & $\lambda$/Year & $\mathbb{E}[J]$ & $\mathbb{E}[S]$/Year & VaR 95\% & CVaR 95\% \\
\midrule
Pre-Crisis & 12.3 & 0.209 & 2.57 & 4.15 & 4.92 \\
\textbf{COVID} & \textbf{17.3} & \textbf{0.262} & \textbf{4.53} & \textbf{7.44} & \textbf{9.65} \\
Post-COVID & 11.6 & 0.188 & 2.19 & 3.44 & 3.85 \\
Recent & 13.6 & 0.216 & 2.95 & 4.70 & 5.63 \\
\midrule
Full Sample & 12.6 & 0.211 & 2.67 & 4.24 & 5.01 \\
\bottomrule
\end{tabular}
\caption{Compound Poisson parameters across market regimes.}
\end{table}

\subsection{Key Regime Findings}

\begin{keyresult}
The COVID regime exhibits:
\begin{itemize}
    \item \textbf{41\% higher arrival rate}: $\lambda_{\text{COVID}} = 17.3$ vs $\lambda_{\text{Pre}} = 12.3$
    \item \textbf{25\% larger mean jumps}: $\mathbb{E}[J]_{\text{COVID}} = 0.262$ vs $\mathbb{E}[J]_{\text{Pre}} = 0.209$
    \item \textbf{76\% higher expected annual impact}: $\mathbb{E}[S]_{\text{COVID}} = 4.53$ vs $\mathbb{E}[S]_{\text{Pre}} = 2.57$
    \item \textbf{Nearly double VaR}: VaR$_{\text{COVID}} = 7.44$ vs VaR$_{\text{Pre}} = 4.15$
\end{itemize}
\end{keyresult}

This decomposition shows that crisis periods are characterized by \emph{both} more frequent shocks \emph{and} larger individual shocks---a double amplification of risk.

\subsection{Regime Comparison Visualization}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{cpp_regime.png}
\caption{Comparison of CPP parameters across market regimes. COVID period shows elevated values across all metrics.}
\end{figure}

% ============================================================
\section{Out-of-Sample Evaluation}
% ============================================================

An essential test of any forecasting model is its out-of-sample performance. We evaluate the CPP model by training on historical data and testing its predictions on a held-out sample.

\subsection{Train-Test Split Design}

We adopt the standard train-test split approach:
\begin{itemize}
    \item \textbf{Training Period:} January 2010 -- December 2021 (75\% of data, $\approx$3,100 observations)
    \item \textbf{Test Period:} January 2022 -- November 2025 (25\% of data, $\approx$1,036 observations)
\end{itemize}

This split corresponds to approximately 12 years of training data and 4 years of out-of-sample testing.

\subsection{Forecasting Methodology}

Given the CPP model fitted on training data with parameters $(\hat{\lambda}, \hat{F})$:

\begin{enumerate}
    \item \textbf{Shock Count Forecast:} For a test period of $T$ days:
    \begin{equation}
    \hat{N}(T) = \hat{\lambda} \cdot T
    \end{equation}
    
    \item \textbf{Cumulative Impact Forecast:}
    \begin{equation}
    \boxed{\hat{S}(T) = \hat{\lambda} \cdot \hat{\mathbb{E}}[J] \cdot T}
    \end{equation}
    
    \item \textbf{Risk Bounds:} Scale VaR and CVaR to the test period:
    \begin{equation}
    \text{VaR}_{T} = \text{VaR}_{1\,\text{year}} \times \frac{T}{252}
    \end{equation}
\end{enumerate}

\subsection{Out-of-Sample Results}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Metric & Value & Notes \\
\midrule
\multicolumn{3}{l}{\textit{Trained Parameters (2010--2021)}} \\
$\hat{\lambda}$ & 0.050/day & 12.6 shocks/year \\
$\hat{F}$ & Pareto & $\alpha = 2.50$, $x_{\min} = 0.127$ \\
$\hat{\mathbb{E}}[J]$ & 0.211 & Mean jump size \\
$\hat{\text{Std}}[J]$ & 0.189 & Jump volatility \\
\midrule
\multicolumn{3}{l}{\textit{Test Period (2022--2025)}} \\
Test Days & 1,036 & Approx.\ 4 years \\
\midrule
\multicolumn{3}{l}{\textit{Shock Count}} \\
Actual Shocks & 63 & Observed \\
Predicted Shocks & 51.8 & $\hat{\lambda} \times 1036$ \\
Error & $-17.8\%$ & Underforecast \\
\midrule
\multicolumn{3}{l}{\textit{Cumulative Impact}} \\
Actual Impact & 13.4 & $\sum_i |J_i|$ \\
Predicted Impact & 10.9 & $\hat{\lambda} \cdot \hat{\mathbb{E}}[J] \cdot T$ \\
Error & $-18.5\%$ & Underforecast \\
\midrule
\multicolumn{3}{l}{\textit{Risk Measures}} \\
Scaled VaR 95\% & 15.2 & For test period \\
VaR Exceeded? & No & Actual $<$ VaR \\
\bottomrule
\end{tabular}
\caption{CPP out-of-sample forecast evaluation results.}
\end{table}

\subsection{Interpretation of Results}

\begin{enumerate}
    \item \textbf{Underforecast Explanation:} The $\sim$18\% underforecast is attributable to:
    \begin{itemize}
        \item \textbf{2022 Fed Rate Hikes:} Aggressive monetary tightening caused elevated VIX volatility
        \item \textbf{2023 Banking Stress:} SVB collapse and regional banking crisis
        \item \textbf{2024 August Volatility:} Yen carry trade unwinding spike
    \end{itemize}
    The test period was unusually volatile compared to the training sample.
    
    \item \textbf{Distribution Calibration:} Monte Carlo simulation shows the actual outcome falls at the \textbf{72nd percentile} of the predicted distribution---well within the expected range, not in the tail.
    
    \item \textbf{VaR Coverage:} The actual cumulative impact (13.4) did NOT exceed the scaled VaR 95\% (15.2), demonstrating that the risk measure is appropriately conservative.
    
    \item \textbf{Parameter Stability:} Re-fitting CPP on the test period alone yields $\alpha \approx 2.6$ (Pareto), confirming the tail index is stable across samples.
\end{enumerate}

\begin{keyresult}
The CPP model demonstrates reasonable out-of-sample performance:
\begin{itemize}
    \item Forecast errors of $\sim$18\% are acceptable given the unusual test period volatility
    \item VaR and CVaR bounds are \textbf{not exceeded}, confirming conservative risk estimates
    \item The model is \textbf{well-calibrated}---actual outcomes are not in the tail of predicted distributions
\end{itemize}
\end{keyresult}

\subsection{Visualization of Out-of-Sample Performance}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{cpp_forecast.png}
\caption{CPP out-of-sample evaluation. Histogram shows simulated test period impacts using trained CPP parameters. Red dashed line indicates actual test period cumulative impact. The actual outcome falls within the bulk of the distribution, demonstrating good calibration.}
\end{figure}

% ============================================================
\section{Connection to Other Models}
% ============================================================

\subsection{CPP vs. Hawkes Process}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
Aspect & Hawkes & Compound Poisson \\
\midrule
Models timing? & Yes & Yes \\
Models magnitude? & No & \textbf{Yes} \\
Self-excitation? & \textbf{Yes} & No \\
Arrival rate & Time-varying & Constant \\
Risk quantification & Limited & \textbf{VaR/CVaR} \\
\bottomrule
\end{tabular}
\caption{Comparison of Hawkes and Compound Poisson Process capabilities.}
\end{table}

\subsection{Potential Extensions}

\begin{enumerate}
    \item \textbf{Hawkes-Compound Process}: Replace Poisson arrivals with Hawkes arrivals:
    \begin{equation}
    S(t) = \sum_{i=1}^{N_H(t)} J_i
    \end{equation}
    where $N_H(t)$ follows a Hawkes process. This captures both self-excitation and jump magnitudes.
    
    \item \textbf{Marked Hawkes Process}: Make jump size depend on history:
    \begin{equation}
    J_i | \mathcal{F}_{t_i^-} \sim F(\cdot; \lambda(t_i^-))
    \end{equation}
    
    \item \textbf{Regime-Switching CPP}: Allow $(\lambda, F)$ to depend on a latent regime variable.
\end{enumerate}

% ============================================================
\section{Practical Implications}
% ============================================================

\subsection{Risk Management}

\begin{enumerate}
    \item \textbf{Capital Allocation}: Use VaR/CVaR estimates to set aside appropriate capital buffers for VIX-related exposures.
    
    \item \textbf{Stress Testing}: The regime-specific parameters provide realistic scenarios:
    \begin{itemize}
        \item Normal year: $\mathbb{E}[S] \approx 2.6$, VaR $\approx 4.2$
        \item Crisis year: $\mathbb{E}[S] \approx 4.5$, VaR $\approx 7.4$
    \end{itemize}
    
    \item \textbf{Dynamic Hedging}: As regime shifts are detected, adjust hedge ratios based on regime-specific $\mathbb{E}[S]$ and VaR.
\end{enumerate}

\subsection{Derivatives Pricing}

The CPP framework is directly applicable to pricing VIX derivatives:
\begin{itemize}
    \item \textbf{VIX Options}: The heavy-tailed Pareto distribution justifies out-of-the-money option premiums.
    \item \textbf{Variance Swaps}: $\mathbb{E}[S]$ relates to expected future variance.
    \item \textbf{Corridor Variance Swaps}: Regime-specific parameters inform fair pricing across market conditions.
\end{itemize}

% ============================================================
\section{Conclusion}
% ============================================================

We studied two complementary frameworks for modeling VIX dynamics over 2010--2025:

\begin{enumerate}
    \item \textbf{Volatility clustering (ARIMA + GARCH-family):} After modeling $d_t=\Delta\log(\mathrm{VIX})_t$ with an ARIMA$(1,0,1)$ mean equation, GARCH-family conditional variance models capture time-varying volatility. Model selection by BIC favors \textbf{EGARCH$(1,1)$ with Student-\emph{t} innovations} over GARCH$(1,1)$, supporting asymmetric volatility responses. Both models imply a volatility shock half-life of roughly \textbf{5 trading days}, consistent with volatility clustering that decays over about one week.
    
    \item \textbf{Jump/shock risk (Compound Poisson Process):} VIX shock magnitudes follow a Pareto distribution with tail index $\alpha = 2.50$, confirming heavy-tailed behavior. Expected annual shock impact is 2.67, with VaR (95\%) = 4.24 and CVaR (95\%) = 5.01. Regime analysis shows crisis periods exhibit both more frequent and larger shocks, and out-of-sample testing indicates conservative VaR coverage.
\end{enumerate}

Overall, the results support the view that \textbf{GARCH/EGARCH and CPP are complementary}: GARCH-family models explain smooth, persistent volatility dynamics, while CPP isolates and quantifies tail shock risk through explicit modeling of shock timing and magnitude.

% ============================================================
\section*{Appendix: Key Formulas Summary}
% ============================================================

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
Quantity & Formula \\
\midrule
CPP Definition & $S(t) = \sum_{i=1}^{N(t)} J_i$ \\[0.5em]
Expected Value & $\mathbb{E}[S(t)] = \lambda t \cdot \mathbb{E}[J]$ \\[0.5em]
Variance & $\text{Var}(S(t)) = \lambda t \cdot \mathbb{E}[J^2]$ \\[0.5em]
MGF & $M_{S(t)}(\theta) = \exp(\lambda t \cdot (M_J(\theta) - 1))$ \\[0.5em]
Pareto PDF & $f(x) = \frac{\alpha x_m^\alpha}{x^{\alpha+1}}$ for $x \geq x_m$ \\[0.5em]
Pareto Mean & $\mathbb{E}[J] = \frac{\alpha x_m}{\alpha - 1}$ for $\alpha > 1$ \\[0.5em]
VaR Definition & $\text{VaR}_\alpha = F_{S(T)}^{-1}(\alpha)$ \\[0.5em]
CVaR Definition & $\text{CVaR}_\alpha = \mathbb{E}[S(T) | S(T) \geq \text{VaR}_\alpha]$ \\
\bottomrule
\end{tabular}
\caption{Summary of key Compound Poisson Process formulas.}
\end{table}

% ============================================================
\section*{References}
% ============================================================

\begin{itemize}
    \item Cont, R., \& Tankov, P. (2004). \textit{Financial Modelling with Jump Processes}. Chapman \& Hall/CRC.
    \item McNeil, A. J., Frey, R., \& Embrechts, P. (2015). \textit{Quantitative Risk Management: Concepts, Techniques and Tools}. Princeton University Press.
    \item Ross, S. M. (2014). \textit{Introduction to Probability Models}. Academic Press.
    \item Madan, D. B., \& Seneta, E. (1990). The variance gamma model for share market returns. \textit{Journal of Business}, 63(4), 511--524.
\end{itemize}

\end{document}
